{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90447204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import  Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re,string,unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fbf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/data/review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de colonnes et rangs : {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Stopwords en anglais\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"suprrimer les htmls et les [] et les contenus dedans\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        text = re.sub('\\[.*?\\]', '', text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning text: {e}\")\n",
    "        text = \"\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# appliquer\n",
    "df['review'] = df['review'].apply(clean_text)\n",
    "\n",
    "#enlever des caractères spéciales\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "#appliquer sur le colonne de commentaire\n",
    "df['review']=df['review'].apply(remove_special_characters)\n",
    "\n",
    "#Lemmatisation\n",
    "def stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(stemmer)\n",
    "\n",
    "#Enlever stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stop]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stop]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "# appliquer\n",
    "df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer BERT et Tokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=True)\n",
    "\n",
    "# construire Tokenizer\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "# préparer les datas\n",
    "input_data = convert_sentences_to_features(df['review'], tokenizer)\n",
    "\n",
    "# construire le modèle\n",
    "input_word_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_mask\")\n",
    "input_type_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "\n",
    "bert_inputs = [input_word_ids, input_mask, input_type_ids]\n",
    "bert_output = bert_layer(bert_inputs)[1]\n",
    "\n",
    "dense = Dense(256, activation='relu')(bert_output)\n",
    "dropout = Dropout(0.5)(dense)\n",
    "output = Dense(1, activation='sigmoid')(dropout)  #2 types\n",
    "\n",
    "model = Model(inputs=bert_inputs, outputs=output)\n",
    "model.compile(Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tonkenizer(model.layers[3])\n",
    "\n",
    "#utiliser les chiffres binaire\n",
    "df['sentiment'].replace('positive',1.,inplace=True)\n",
    "df['sentiment'].replace('negative',0.,inplace=True)\n",
    "\n",
    "#mélanger le train et les ensembles de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], shuffle = True, test_size=0.20)\n",
    "\n",
    "X_train = convert_sentences_to_features(X_train, tokenizer)\n",
    "X_test = convert_sentences_to_features(X_test, tokenizer)\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test =  to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea50511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "\n",
    "# Adam optimizer pour minimiser la perte categorical_crossentropy\n",
    "opt = Adam(learning_rate=2e-5)\n",
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Ajuster les données au modèle\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    verbose = 1)\n",
    "\n",
    "# Enregistrer le modèle entraîné\n",
    "model.save('nlp_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab78ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer le modèle entraîné\n",
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('nlp_model.h5',custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65193ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predire sur test-set\n",
    "from sklearn.metrics import classification_report\n",
    "pred_test = np.argmax(new_model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af998e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1), pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
